{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /Users/lisakoopmans/miniforge3/envs/mlp/lib/python3.8/site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /Users/lisakoopmans/miniforge3/envs/mlp/lib/python3.8/site-packages (from scipy) (1.22.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "!{sys.executable} -m pip install scipy\n",
    "from scipy.stats import f_oneway"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cs(gt, pred, alpha):\n",
    "    \"\"\"\n",
    "    Computes the Cumulative Score with given alpha\n",
    "\n",
    "    :param gt:    Ground truths\n",
    "    :param pred:  Predicted dates\n",
    "    :param alpha: Acceptable error range in years\n",
    "\n",
    "    :return: The CS with given alpha\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i in range(len(gt)):\n",
    "        absolute_error = abs(gt[i] - pred[i])\n",
    "        if absolute_error <= alpha:\n",
    "            count += 1\n",
    "\n",
    "    return count / len(gt) * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cv(model, features, labels, k, seed):\n",
    "    \"\"\"\n",
    "    Performs stratisfied k-fold cross-validation.\n",
    "\n",
    "    :param model:    The model to train\n",
    "    :param features: Features to train and test the model with\n",
    "    :param labels:   Labels of the features\n",
    "    :param k:        Number of folds for the cross-validation\n",
    "    :param seed:     Seed for splitting data into test/train sets\n",
    "\n",
    "    :return: Mean and SD of MAE, CS with alpha = 25 and alpha = 0 years across all folds.\n",
    "    \"\"\"\n",
    "    mae_k = []\n",
    "    cs_k = []\n",
    "    cs_1 = []\n",
    "    # As the dataset is imbalanced --> stratified kfold + seed to get the same validation/train splits\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "\n",
    "    for train_index, test_index in kf.split(features, labels):\n",
    "        # Getting test and train sets\n",
    "        train_features, test_features = features[train_index], features[test_index]\n",
    "        train_labels, test_labels = [labels[i] for i in train_index], [labels[i] for i in test_index]\n",
    "\n",
    "        # Training model and predicting dates on test data\n",
    "        model.fit(train_features, train_labels)\n",
    "        pred = model.predict(test_features)\n",
    "        pred = [int(i) for i in pred]\n",
    "\n",
    "        mae_k.append(mae(test_labels, pred))\n",
    "        cs_k.append(cs(test_labels, pred, 25))\n",
    "        cs_1.append(cs(test_labels, pred, 0))\n",
    "\n",
    "    return mae_k, cs_k, cs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def kfold_cv_aug(model, features_norm, features_aug, labels_norm, labels_aug, k, n_aug, seed):\n",
    "    \"\"\"\n",
    "    Performs stratisfied k-fold cross-validation for augmented data.\n",
    "\n",
    "    :param model:         The model to train\n",
    "    :param features_norm: Features of non-augmented images\n",
    "    :param features_aug:  Features of augmented images\n",
    "    :param labels_norm:   Labels of the non-augmented features\n",
    "    :param labels_aug:    Labels of the augmented features\n",
    "    :param k:             Number of folds for the cross-validation\n",
    "    :param n_aug:         Number of augmented images per non-augmented image\n",
    "    :param seed:          Seed for splitting data into test/train sets\n",
    "\n",
    "    :return: Mean and SD of MAE, CS with alpha = 25 and alpha = 0 years across all folds.\n",
    "    \"\"\"\n",
    "    mae_k = []\n",
    "    cs_k = []\n",
    "    cs_1 = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=seed)\n",
    "    for train_index, test_index in tqdm.tqdm(kf.split(features_norm, labels_norm)):\n",
    "        # Getting test and train sets from non-augmented labels and features\n",
    "        test = [features_norm[idx] for idx in test_index]\n",
    "        test_labels = [labels_norm[idx] for idx in test_index]\n",
    "\n",
    "        train = [features_norm[idx] for idx in train_index]\n",
    "        train_labels = [labels_norm[idx] for idx in train_index]\n",
    "\n",
    "        # Getting test and training sets from augmented labels and features\n",
    "        for idx in range(len(features_aug)):\n",
    "            if int(idx/n_aug) in test_index:\n",
    "                continue\n",
    "            else:\n",
    "                train.append(features_aug[idx])\n",
    "                train_labels.append(labels_aug[idx])\n",
    "\n",
    "        # Training the model and predicting dates\n",
    "        model.fit(train, train_labels)\n",
    "        pred = model.predict(test)\n",
    "        pred = [int(i) for i in pred]\n",
    "\n",
    "        mae_k.append(mae(test_labels, pred))\n",
    "        cs_k.append(cs(test_labels, pred, 25))\n",
    "        cs_1.append(cs(test_labels, pred, 0))\n",
    "\n",
    "    return mae_k, cs_k, cs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, train_features, test_features, train_labels, test_labels, plot_bool=0):\n",
    "    \"\"\"\n",
    "    Predicts dates with a given model and displays a scatter plot of \n",
    "    the ground truth and predicted dates.\n",
    "\n",
    "    :param model:          The model to train\n",
    "    :param train_features: Features to train the model witb\n",
    "    :param test_features:  Features to test the model with\n",
    "    :param train_labels:   Labels of train features\n",
    "    :param test_labels:    Labels of test features\n",
    "    :param plot_bool:      Boolean if plot should be produced\n",
    "\n",
    "    :return: Mean Absolute Error (MAE) and Cumulative Score with alpha-values 25 and 0\n",
    "    \"\"\"\n",
    "    model.fit(train_features, train_labels)\n",
    "    pred = model.predict(test_features)\n",
    "    pred = [int(i) for i in pred]\n",
    "\n",
    "    if plot_bool:\n",
    "        plt.scatter(test_labels, pred)\n",
    "        plt.ylabel('pred')\n",
    "        plt.xlabel('true')\n",
    "        plt.show()\n",
    "    return round(mae(test_labels, pred), 4), round(cs(test_labels, pred, 25), 4), round(cs(test_labels, pred, 1), 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatType():\n",
    "    HINGE = 0\n",
    "    JUNC = 1\n",
    "\n",
    "class Data():\n",
    "    def __init__(self, name, feat_dir, feat_aug_dir, k, n_aug):\n",
    "        self.name = name\n",
    "        self.feat_dir = feat_dir\n",
    "        self.feat_aug_dir = feat_aug_dir\n",
    "        self.k_folds = k\n",
    "        self.n_aug = n_aug\n",
    "        if name == \"EEA\":\n",
    "            self.test_indices = np.load('./Data/DSS/test_indices.npy')\n",
    "        elif name == \"MPS\":\n",
    "            self.test_indices = np.load('./tfsom/MPS/test_indices.npy')\n",
    "        elif name == \"Himanis\":\n",
    "            self.test_indices_hinge = np.load('./Data/Himanis/Himanis_test_indices_hinge.npy')\n",
    "            self.test_indices_junclets = np.load('./Data/Himanis/Himanis_test_indices_junclets.npy')\n",
    "    \n",
    "    def set_cb_size(self, cb_size):\n",
    "        self.cb_size = cb_size\n",
    "    \n",
    "    def set_kernel(self, kernel):\n",
    "        self.kernel = kernel\n",
    "\n",
    "    def set_Cs(self, Cs):\n",
    "        self.Cs = Cs\n",
    "    \n",
    "    def set_Cs_aug(self, Cs):\n",
    "        self.Cs_aug = Cs\n",
    "\n",
    "EEA = Data(\"EEA\", \"./Data/DSS/features/\", \"./Data/DSS/features/features_aug_15/\", k=4, n_aug=15)\n",
    "MPS = Data(\"MPS\", \"./tfsom/MPS/all/\", \"./tfsom/MPS/all/\", k=10, n_aug=3)\n",
    "HIMANIS = Data(\"Himanis\", \"./Data/Himanis/features/\", \"./Data/Himanis/features/\", k=10, n_aug=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_features(features):\n",
    "    \"\"\"\n",
    "    Rescales features between 0 and 1\n",
    "    \"\"\"\n",
    "    features = np.asarray(features)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(features)\n",
    "    data_rescaled = scaler.transform(features)\n",
    "\n",
    "    return data_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_features_split(features1, features2):\n",
    "    \"\"\"\n",
    "    Rescales features between 0 and 1 in the case of 2 split sets of features    \n",
    "    \"\"\"\n",
    "    features1 = np.array(features1)\n",
    "    features2 = np.array(features2)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(np.concatenate((features1, features2), axis=0))\n",
    "    data_rescaled1 = scaler.transform(features1)\n",
    "    data_rescaled2 = scaler.transform(features2)\n",
    "    return data_rescaled1, data_rescaled2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features2(feature_dir, hinge_or_junc, dataset):\n",
    "    \"\"\"\n",
    "    Reads feature vectors from files in a directory\n",
    "\n",
    "    :param feature_dir:   Directory containing feature files\n",
    "    :param hinge_or_junc: Boolean value whether feature is from Hinge family (0) \n",
    "                          or is the Junclets feature (1)\n",
    "    :param n_aug:         Number of augmented images per non-augmented image\n",
    "\n",
    "    :return: List of feature vectors and corresponding labels (key years)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    count = 0\n",
    "    nan_count = 0\n",
    "    print(dataset.n_aug, feature_dir)\n",
    "\n",
    "    # Iterating over all feature files\n",
    "    for file in sorted(os.listdir(feature_dir)):\n",
    "        aug_num = re.search(\"(_[0-9]?[0-9].p)\", file)\n",
    "\n",
    "        if aug_num is not None:\n",
    "            aug_num = re.search(\"([0-9]?[0-9])\", aug_num.group())\n",
    "        if aug_num is None or (aug_num is not None and int(aug_num.group()) <= dataset.n_aug):\n",
    "            if file != \".DS_Store\" and not os.path.isdir(feature_dir + '/' + file):\n",
    "                f = open(feature_dir + \"/\" + file)\n",
    "                # Gets the file's feature vector\n",
    "                for line in f.readlines():\n",
    "                    line = line.rstrip().split(\" \")\n",
    "                    if hinge_or_junc == FeatType.HINGE:\n",
    "                        features.append(line[2:])\n",
    "                    elif hinge_or_junc == FeatType.JUNC:\n",
    "                        features.append([float(el) for el in line])\n",
    "                        count += 1\n",
    "\n",
    "                    if dataset.name == EEA.name:\n",
    "                        label = re.search(\"(-?[0-9][0-9][0-9])\", file)\n",
    "                    elif dataset.name == MPS.name:\n",
    "                        label = re.search(\"([0-9][0-9][0-9][0-9])\", file) \n",
    "                    elif dataset.name == HIMANIS.name:\n",
    "                        label = re.search(\"13([0-9][0-9])\", file) \n",
    "\n",
    "                    \n",
    "                    labels.append(int(label.group()))\n",
    "    print(nan_count)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(featuredir, size, dataset):\n",
    "    \"\"\"\n",
    "    Returns features and labels in a directory\n",
    "    \"\"\"\n",
    "    if featuredir != 'junclets' and featuredir != 'test/junclets':\n",
    "        features, labels = get_features2(dataset.feat_dir + featuredir, FeatType.HINGE, dataset)\n",
    "    elif featuredir == 'junclets':\n",
    "        prefix = dataset.feat_dir + featuredir + '/size_' + str(size) + '/'\n",
    "        features, labels = get_features2(prefix, FeatType.JUNC, dataset)\n",
    "    return features, labels\n",
    "\n",
    "def get_features_aug(featuredir, size, dataset):\n",
    "    \"\"\"\n",
    "    Returns features and labels in a directory of both non-augmented and augmented images\n",
    "    \"\"\"\n",
    "    if featuredir != 'junclets':\n",
    "        features_norm, labels_norm = get_features2(dataset.feat_dir + featuredir, FeatType.HINGE, dataset)\n",
    "        features_aug, labels_aug = get_features2(dataset.feat_aug_dir + featuredir + '_aug', FeatType.HINGE, dataset)\n",
    "    else:\n",
    "        suffix = '/size_' + str(size) + '/'\n",
    "        features_norm, labels_norm = get_features2(dataset.feat_dir + featuredir + suffix, FeatType.JUNC, dataset)\n",
    "        features_aug, labels_aug = get_features2(dataset.feat_aug_dir + featuredir + '_aug/' + suffix, FeatType.JUNC, dataset)\n",
    "\n",
    "    return features_norm, labels_norm, features_aug, labels_aug"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting indices for test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPS\n",
    "size_data = 3267\n",
    "test_size = 0.1 #as a fraction\n",
    "test_indices = np.random.choice(np.array([i for i in range(size_data)]), int(size_data * test_size), replace=False)\n",
    "test_idx_path = './test_indices.npy'\n",
    "if not os.path.exists(test_idx_path):\n",
    "    np.save(test_idx_path, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Himanis\n",
    "size_data = 789\n",
    "test_size = 0.1 #as a fraction\n",
    "test_indices = np.random.choice(np.array([i for i in range(size_data)]), int(size_data * test_size), replace=False)\n",
    "test_idx_path = './Data/Himanis/Himanis_test_indices_hinge.npy'\n",
    "if not os.path.exists(test_idx_path):\n",
    "    np.save(test_idx_path, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Himanis\n",
    "size_data = 394\n",
    "test_size = 0.1 #as a fraction\n",
    "test_indices = np.random.choice(np.array([i for i in range(size_data)]), int(size_data * test_size), replace=False)\n",
    "test_idx_path = './Data/Himanis/Himanis_test_indices_junclets.npy'\n",
    "\n",
    "if not os.path.exists(test_idx_path):\n",
    "    np.save(test_idx_path, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EA and DSS\n",
    "idx = 0\n",
    "for file in sorted(os.listdir('./Data/DSS//DSS_jpg_re/')):\n",
    "    label = re.search(\"(-?[0-9][0-9][0-9])\", file)\n",
    "    idx += 1\n",
    "\n",
    "np.save('./Data/DSS/test_indices.npy', [0, 5, 6, 16, 17])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter tuning\n",
    "Original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Hinge features\n",
    "dataset = EEA\n",
    "\n",
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge']\n",
    "\n",
    "Cs = [pow(2, n) for n in range(-7, 10, 1)]  # hyper-parameter range of values\n",
    "seeds = [0, 50, 100, 150, 200, 250]\n",
    "\n",
    "# Iterates over all features\n",
    "for featuredir in feat_names:\n",
    "    print(featuredir)\n",
    "\n",
    "    # Getting the feature vectors and labels\n",
    "    features, labels = get_features(featuredir, 0, dataset)\n",
    "    features = rescale_features(features)\n",
    "\n",
    "    # Getting the test set\n",
    "    test_indices = dataset.test_indices_hinge if dataset.name == HIMANIS.name else dataset.test_indices\n",
    "    \n",
    "    test = [features[idx] for idx in test_indices]\n",
    "    test_labels = [labels[idx] for idx in test_indices]\n",
    "\n",
    "    # Getting the train set\n",
    "    train = []\n",
    "    train_labels = []\n",
    "    for idx in range(len(features)):\n",
    "        if idx not in test_indices:\n",
    "            train.append(features[idx])\n",
    "            train_labels.append(labels[idx])\n",
    "\n",
    "    results = [[0, 0, 0, 0, 0, 0, 0] for _ in range(len(Cs))]\n",
    "    best_set = {'kernel':'linear', 'C':0, 'MAE':[], 'CS_25':[], 'CS_0':[], 'mean_cs_0':0.0}\n",
    "    for c_idx in range(len(Cs)):\n",
    "            results[c_idx][0] = Cs[c_idx]\n",
    "            res_mae = []\n",
    "            res_cs_25 = []\n",
    "            res_cs_0 = []\n",
    "            for seed in seeds:\n",
    "                clf = kfold_cv(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[c_idx]), np.array(train), np.array(train_labels), dataset.k_folds, seed)\n",
    "                res_mae.append(clf[0])\n",
    "                res_cs_25.append(clf[1])\n",
    "                res_cs_0.append(clf[2])\n",
    "                mean_clf = [np.mean(clf[0]), np.std(clf[0]), np.mean(clf[1]), np.std(clf[1]), np.mean(clf[2]), np.std(clf[2])]\n",
    "                for res_idx in range(len(mean_clf)):\n",
    "                    results[c_idx][res_idx + 1] += mean_clf[res_idx]\n",
    "            for res_idx in range(1, len(results[c_idx])):\n",
    "                    results[c_idx][res_idx] = results[c_idx][res_idx]/len(seeds)\n",
    "            print(Cs[c_idx], results[c_idx][5], results[c_idx][6])\n",
    "            accuracy = results[c_idx][5]\n",
    "    \n",
    "            if accuracy > best_set['mean_cs_0']:\n",
    "                best_set['C'] = Cs[c_idx]\n",
    "                best_set['MAE'] = res_mae\n",
    "                best_set['CS_25'] = res_cs_25\n",
    "                best_set['CS_0'] = res_cs_0\n",
    "                best_set['mean_cs_0'] = accuracy\n",
    "    print(np.mean(best_set['CS_0']))\n",
    "            \n",
    "    if dataset.name == HIMANIS.name:\n",
    "        np.save('./Data/Himanis/validation_results/' + featuredir + '_validation.npy', best_set)\n",
    "    if dataset.name == MPS.name:\n",
    "        np.save('./Data/MPS/validation_results/' + featuredir + '_validation.npy', best_set)\n",
    "    if dataset.name == EEA.name:\n",
    "        np.save('./Data/EEA/validation_results/' + featuredir + '_validation.npy', best_set)\n",
    "        \n",
    "    print(best_set)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning for codebook sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset = EEA\n",
    "featuredir = 'junclets'\n",
    "\n",
    "Cs = [pow(2, n) for n in range(-7,10, 1)]\n",
    "seeds = [0, 50, 100, 150, 200, 250]\n",
    "\n",
    "# Iterates over all sub-codebook sizes\n",
    "for cb_size in range(5, 35, 5):\n",
    "    print(cb_size)\n",
    "\n",
    "    # Getting the feature vectors and labels\n",
    "    features, labels = get_features(featuredir, cb_size, dataset)\n",
    "    features = rescale_features(features)\n",
    "\n",
    "    # Getting the test set\n",
    "    test_indices = dataset.test_indices_junclets if dataset.name == HIMANIS.name else dataset.test_indices\n",
    "    test = [features[idx] for idx in test_indices]\n",
    "    test_labels = [labels[idx] for idx in test_indices]\n",
    "\n",
    "    # Getting the train set\n",
    "    train = []\n",
    "    train_labels = []\n",
    "    for idx in range(len(features)):\n",
    "        if idx not in test_indices:\n",
    "            train.append(features[idx])\n",
    "            train_labels.append(labels[idx])\n",
    "\n",
    "    results = [[0, 0, 0, 0, 0, 0, 0] for _ in range(len(Cs))]\n",
    "    best_set = {'kernel':'linear', 'C':0, 'MAE':[], 'CS_25':[], 'CS_0':[], 'mean_cs_0':0.0}\n",
    "\n",
    "    # Cross-validation across all seeds and hyper-parameter values\n",
    "    for c_idx in range(len(Cs)):\n",
    "            results[c_idx][0] = Cs[c_idx]\n",
    "            res_mae = []\n",
    "            res_cs_25 = []\n",
    "            res_cs_0 = []\n",
    "            for seed in seeds:\n",
    "                clf = kfold_cv(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[c_idx]), np.array(train), np.array(train_labels), dataset.k_folds, seed)\n",
    "                res_mae.append(clf[0])\n",
    "                res_cs_25.append(clf[1])\n",
    "                res_cs_0.append(clf[2])\n",
    "                mean_clf = [np.mean(clf[0]), np.std(clf[0]), np.mean(clf[1]), np.std(clf[1]), np.mean(clf[2]), np.std(clf[2])]\n",
    "                for res_idx in range(len(mean_clf)):\n",
    "                    results[c_idx][res_idx + 1] += mean_clf[res_idx]\n",
    "            for res_idx in range(1, len(results[c_idx])):\n",
    "                    results[c_idx][res_idx] = results[c_idx][res_idx]/len(seeds)\n",
    "            print(Cs[c_idx], results[c_idx][5], results[c_idx][6])\n",
    "            accuracy = results[c_idx][5]\n",
    "    \n",
    "            if accuracy > best_set['mean_cs_0']:\n",
    "                best_set['C'] = Cs[c_idx]\n",
    "                best_set['MAE'] = res_mae\n",
    "                best_set['CS_25'] = res_cs_25\n",
    "                best_set['CS_0'] = res_cs_0\n",
    "                best_set['mean_cs_0'] = accuracy\n",
    "\n",
    "    if dataset.name == HIMANIS.name:\n",
    "        np.save('./Data/Himanis/validation_results/' + featuredir + '_' + str(cb_size) + '_validation.npy', best_set)\n",
    "    elif dataset.name == MPS.name:\n",
    "        np.save('./Data/MPS/validation_results/' + featuredir + '_' + str(cb_size) + '_validation.npy', best_set)\n",
    "    elif dataset.name == EEA.name:\n",
    "        np.save('./Data/EEA/validation_results/' + featuredir + '_' + str(cb_size) + '_validation.npy', best_set)\n",
    "    print(best_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge', 'junclets']\n",
    "dataset = EEA\n",
    "\n",
    "EEA.set_cb_size(15)\n",
    "MPS.set_cb_size(25)\n",
    "HIMANIS.set_cb_size(10)\n",
    "\n",
    "Cs = [pow(2, n) for n in range(-7,10, 1)] # range of values for hyper-parameter\n",
    "seeds = [0, 50, 100, 150, 200, 250]\n",
    "\n",
    "# Iterates over all features\n",
    "for featuredir in feat_names:\n",
    "    print(featuredir)\n",
    "         \n",
    "    # Getting feature vectors and labels\n",
    "    features_norm, labels_norm, features_aug, labels_aug = get_features_aug(featuredir, dataset.cb_size, dataset)\n",
    "    features_norm, features_aug = rescale_features_split(features_norm, features_aug)\n",
    "\n",
    "    # Getting test set\n",
    "    if featuredir == 'junclets':\n",
    "        test_indices = dataset.test_indices_junclets if dataset.name == HIMANIS.name else dataset.test_indices\n",
    "    else:\n",
    "        test_indices = dataset.test_indices_hinge if dataset.name == HIMANIS.name else dataset.test_indices\n",
    "\n",
    "    test = [features_norm[idx] for idx in test_indices]\n",
    "    test_labels = [labels_norm[idx] for idx in test_indices]\n",
    "\n",
    "    # Getting training set from the augmented feature vectors and labels\n",
    "    train_aug = []\n",
    "    train_aug_labels = []\n",
    "    for idx in range(len(features_aug)):\n",
    "        if int(idx/dataset.n_aug) in test_indices:\n",
    "            continue\n",
    "        else:\n",
    "            train_aug.append(features_aug[idx])\n",
    "            train_aug_labels.append(labels_aug[idx])\n",
    "\n",
    "    # Getting training set from the non-augmented feature vectors and labels\n",
    "    train_norm = []\n",
    "    train_norm_labels = []\n",
    "    for idx in range(len(features_norm)):\n",
    "        if idx not in test_indices:\n",
    "            train_norm.append(features_norm[idx])\n",
    "            train_norm_labels.append(labels_norm[idx])\n",
    "            \n",
    "    results = [[0, 0, 0, 0, 0, 0, 0] for i in range(len(Cs))]\n",
    "    best_set = {'kernel':'linear', 'C':0, 'MAE':[], 'CS_25':[], 'CS_0':[], 'mean_cs_0':0.0}\n",
    "\n",
    "    # Cross-validation across all seeds and hyper-parameter values\n",
    "    for c_idx in range(len(Cs)):\n",
    "            results[c_idx][0] = Cs[c_idx]\n",
    "            res_mae = []\n",
    "            res_cs_25 = []\n",
    "            res_cs_0 = []\n",
    "            for seed in seeds:\n",
    "                clf = kfold_cv_aug(svm.SVC(kernel='linear', decision_function_shape='ovr', C=Cs[c_idx]), \n",
    "                                   np.array(train_norm), np.array(train_aug), \n",
    "                                   np.array(train_norm_labels), np.array(train_aug_labels), \n",
    "                                   dataset.k_folds, \n",
    "                                   dataset.n_aug,\n",
    "                                   seed)\n",
    "                res_mae.append(clf[0])\n",
    "                res_cs_25.append(clf[1])\n",
    "                res_cs_0.append(clf[2])\n",
    "                mean_clf = [np.mean(clf[0]), np.std(clf[0]), np.mean(clf[1]), np.std(clf[1]), np.mean(clf[2]), np.std(clf[2])]\n",
    "                for res_idx in range(len(mean_clf)):\n",
    "                    results[c_idx][res_idx + 1] += mean_clf[res_idx]\n",
    "            for res_idx in range(1, len(results[c_idx])):\n",
    "                    results[c_idx][res_idx] = results[c_idx][res_idx]/len(seeds)\n",
    "            print(Cs[c_idx], results[c_idx][5], results[c_idx][6])\n",
    "            accuracy = results[c_idx][5]\n",
    "    \n",
    "            if accuracy > best_set['mean_cs_0']:\n",
    "                best_set['C'] = Cs[c_idx]\n",
    "                best_set['MAE'] = res_mae\n",
    "                best_set['CS_25'] = res_cs_25\n",
    "                best_set['CS_0'] = res_cs_0\n",
    "                best_set['mean_cs_0'] = accuracy\n",
    "    if dataset.name == HIMANIS.name:\n",
    "        np.save('./Data/Himanis/validation_results/' + featuredir + '_validation_aug.npy', best_set)\n",
    "    elif dataset.name == MPS.name:\n",
    "        np.save('./Data/MPS/validation_results/' + featuredir + '_validation_aug.npy', best_set)\n",
    "    elif dataset.name == EEA.name:\n",
    "        np.save('./Data/EEA/validation_results/' + featuredir + '_validation_aug.npy', best_set)\n",
    "    print(best_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EEA\n",
    "file_name = './Data/' + dataset.name + '/validation_results/validation_aug.csv'\n",
    "\n",
    "\n",
    "with open(file_name, mode='w') as file:\n",
    "    if dataset == MPS.name:\n",
    "        file.write('feature, Mean MAE, MAE SD, Mean CS(=25), CS(=25) SD, Mean CS(=0), CS(=0) SD\\n')\n",
    "    else:\n",
    "        file.write('feature, Mean MAE, MAE SD, Mean CS(=0), CS(=0) SD\\n')\n",
    "\n",
    "    for featuredir in ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge', 'junclets']:\n",
    "        print(featuredir)\n",
    "        results_dict = np.load('./Data/' + dataset.name + '/validation_results/' + featuredir + '_validation_aug.npy', allow_pickle=True)\n",
    "        results_dict = results_dict.item()\n",
    "        mae_folds = results_dict['MAE']\n",
    "        cs_0_folds = results_dict['CS_0']\n",
    "        \n",
    "        print(np.mean(mae_folds), np.std(mae_folds), np.mean(cs_0_folds), np.std(cs_0_folds))\n",
    "        \n",
    "        mae_mean = round(np.mean(mae_folds), 2)\n",
    "        mae_sd = round(np.std(mae_folds), 2)\n",
    "        cs_0_mean = round(np.mean(cs_0_folds), 2)\n",
    "        cs_0_sd = round(np.std(cs_0_folds), 2)\n",
    "\n",
    "        if dataset.name == MPS.name:\n",
    "            cs_25_folds = results_dict['CS_25']\n",
    "            cs_25_mean = round(np.mean(cs_25_folds), 2)\n",
    "            cs_25_sd = round(np.std(cs_25_folds), 2)\n",
    "            print(cs_25_sd)\n",
    "            to_write = featuredir + ',' + str(mae_mean) + ',' + str(mae_sd) + ',' + str(cs_25_mean) + ',' + str(cs_25_sd) + ',' + str(cs_0_mean) + ',' + str(cs_0_sd) + '\\n'\n",
    "        else:\n",
    "            to_write = featuredir + ',' + str(mae_mean) + ',' + str(mae_sd) + ',' + str(cs_0_mean) + ',' + str(cs_0_sd) + '\\n'\n",
    "        \n",
    "        file.write(to_write)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuredir = 'junclets'\n",
    "dataset = EEA\n",
    "\n",
    "file_name = './Data/' + dataset.name + '/validation_results/validation_junclets.csv'\n",
    "\n",
    "with open(file_name, mode='w') as file:\n",
    "    if dataset == MPS.name:\n",
    "        file.write('subcodebook size, Mean MAE, MAE SD, Mean CS(=25), CS(=25) SD, Mean CS(=0), CS(=0) SD\\n')\n",
    "    else:\n",
    "        file.write('subcodebook size, Mean MAE, MAE SD, Mean CS(=0), CS(=0) SD\\n')\n",
    "    for cb_size in range(5, 35, 5):\n",
    "        print(cb_size)\n",
    "        results_dict = np.load('./Data/' + dataset.name + '/validation_results/' + featuredir + '_' + str(cb_size) + '_validation.npy', allow_pickle=True)\n",
    "        results_dict = results_dict.item()\n",
    "        mae_folds = results_dict['MAE']\n",
    "        cs_0_folds = results_dict['CS_0']\n",
    "        \n",
    "        print(np.mean(mae_folds), np.std(mae_folds), np.mean(cs_0_folds), np.std(cs_0_folds))\n",
    "        \n",
    "        mae_mean = round(np.mean(mae_folds), 2)\n",
    "        mae_sd = round(np.std(mae_folds), 2)\n",
    "        cs_0_mean = round(np.mean(cs_0_folds), 2)\n",
    "        cs_0_sd = round(np.std(cs_0_folds), 2)\n",
    "\n",
    "        if dataset.name == MPS.name:\n",
    "            cs_25_folds = results_dict['CS_25']\n",
    "            cs_25_mean = round(np.mean(cs_25_folds), 2)\n",
    "            cs_25_sd = round(np.std(cs_25_folds), 2)\n",
    "            print(cs_25_sd)\n",
    "            to_write = str(cb_size) + ',' + str(mae_mean) + ',' + str(mae_sd) + ',' + str(cs_25_mean) + ',' + str(cs_25_sd) + ',' + str(cs_0_mean) + ',' + str(cs_0_sd) + '\\n'\n",
    "        else:\n",
    "            to_write = str(cb_size) + ',' + str(mae_mean) + ',' + str(mae_sd) + ',' + str(cs_0_mean) + ',' + str(cs_0_sd) + '\\n'\n",
    "        \n",
    "        file.write(to_write)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge', 'junclets']\n",
    "\n",
    "EEA.set_kernel('linear')\n",
    "EEA.set_Cs([1, 1, 1, 0.125, 0.125, 0.03125])\n",
    "MPS.set_kernel('linear')\n",
    "MPS.set_Cs([8, 0.0625, 0.125, 1, 1, 0.0625])\n",
    "HIMANIS.set_kernel('linear')\n",
    "HIMANIS.set_Cs([4, 0.03125, 0.25, 0.5, 1, 0.125])\n",
    "HIMANIS.set_cb_size(10)\n",
    "\n",
    "dataset = EEA\n",
    "\n",
    "idx_c = 0\n",
    "\n",
    "file_name = './Data/' + dataset.name + '/validation_results/test.csv'\n",
    "\n",
    "with open(file_name, mode='w') as file:\n",
    "    file.write('feature,MAE,CS(=0)\\n')\n",
    "    for featuredir in feat_names:\n",
    "        print(featuredir)\n",
    "        # Getting feature vectores + labels\n",
    "        features, labels = get_features(featuredir, dataset.cb_size, dataset)\n",
    "        features = rescale_features(features)\n",
    "\n",
    "        # Getting test set\n",
    "        if featuredir == 'junclets':\n",
    "            test_indices = dataset.test_indices_junclets if dataset.name == HIMANIS.name else dataset.test_indices\n",
    "        else:\n",
    "            test_indices = dataset.test_indices_hinge if dataset.name == HIMANIS.name else dataset.test_indices\n",
    "\n",
    "        test = [features[idx] for idx in test_indices]\n",
    "        test_labels = [labels[idx] for idx in test_indices]\n",
    "\n",
    "        # Getting train set\n",
    "        train = []\n",
    "        train_labels = []\n",
    "        for idx in range(len(features)):\n",
    "            if idx not in test_indices:\n",
    "                train.append(features[idx])\n",
    "                train_labels.append(labels[idx])\n",
    "\n",
    "        # Date prediction of test set\n",
    "        print(idx_c, dataset.Cs[idx_c])\n",
    "        mae_res, cs_res25, cs_res1 = test_model(svm.SVC(kernel=dataset.kernel, decision_function_shape='ovr', C=dataset.Cs[idx_c]), train, test, train_labels, test_labels, plot_bool=1)\n",
    "        print(\"MAE: %.4f  \\t CS (=25): %.4f  \\t CS(=1): %.4f \" % (mae_res, cs_res25, cs_res1))\n",
    "        print(\"%.4f,%.4f,%.4f\" % (mae_res, cs_res25, cs_res1))\n",
    "\n",
    "        to_write = featuredir + ',' + str(round(mae_res, 2)) + ',' + str(round(cs_res1, 2)) + '\\n'\n",
    "        file.write(to_write)\n",
    "\n",
    "        idx_c += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "With augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['hinge', 'cohinge', 'quadhinge', 'deltahinge','tcchinge', 'junclets']\n",
    "\n",
    "EEA.set_Cs_aug([1, 1, 1, 2, 0.25, 0.25])\n",
    "MPS.set_Cs_aug([2, 0.0625, 0.0625, 1, 1, 0.0625])\n",
    "HIMANIS.set_Cs_aug([0.125, 0.03125, 0.125, 64, 1, 0.0625])\n",
    "\n",
    "dataset = HIMANIS\n",
    "\n",
    "idx_c = 0\n",
    "file_name = './Data/' + dataset.name + '/validation_results/test_aug.csv'\n",
    "\n",
    "with open(file_name, mode='w') as file:\n",
    "    for featuredir in feat_names:\n",
    "        print(featuredir)\n",
    "        # Getting feature vectors + labels\n",
    "        features_norm, labels_norm, features_aug, labels_aug = get_features_aug(featuredir, dataset.cb_size, dataset)\n",
    "        features_norm, features_aug = rescale_features_split(features_norm, features_aug)\n",
    "\n",
    "        # Test set from non-augmented data\n",
    "        if featuredir == 'junclets':\n",
    "            test_indices = dataset.test_indices_junclets if dataset.name == HIMANIS.name else dataset.test_indices\n",
    "        else:\n",
    "            test_indices = dataset.test_indices_hinge if dataset.name == HIMANIS.name else dataset.test_indices\n",
    "\n",
    "        test = [features_norm[idx] for idx in test_indices]\n",
    "        test_labels = [labels_norm[idx] for idx in test_indices]\n",
    "        \n",
    "        # Train set augmented data\n",
    "        train_aug = []\n",
    "        train_aug_labels = []\n",
    "        for idx in range(len(features_aug)):\n",
    "            if int(idx/dataset.n_aug) in test_indices:\n",
    "                continue\n",
    "            else:\n",
    "                train_aug.append(features_aug[idx])\n",
    "                train_aug_labels.append(labels_aug[idx])\n",
    "\n",
    "        # Train set non-augmented data\n",
    "        train_norm = []\n",
    "        train_norm_labels = []\n",
    "        for idx in range(len(features_norm)):\n",
    "            if idx not in test_indices:\n",
    "                train_norm.append(features_norm[idx])\n",
    "                train_norm_labels.append(labels_norm[idx])\n",
    "\n",
    "        # concatenating augmented and non-augmented train sets\n",
    "        train = train_norm + train_aug\n",
    "        train_labels = train_norm_labels + train_aug_labels\n",
    "        print(len(train), len(train_labels), len(train_aug))\n",
    "\n",
    "        # Date prediction on test set\n",
    "        mae_res, cs_res25, cs_res1 = test_model(svm.SVC(kernel=dataset.kernel, decision_function_shape='ovr', C=dataset.Cs_aug[idx_c]), train, test, train_labels, test_labels, plot_bool=1)\n",
    "        print(\"MAE: %.4f  \\t CS (=25): %.4f  \\t CS(=1): %.4f \" % (mae_res, cs_res25, cs_res1))\n",
    "        print(\"%.4f,%.4f,%.4f\" % (mae_res, cs_res25, cs_res1))\n",
    "\n",
    "        to_write = featuredir + ',' + str(round(mae_res, 2)) + ',' + str(round(cs_res1, 2)) + '\\n'\n",
    "        file.write(to_write)\n",
    "\n",
    "        idx_c += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = EEA\n",
    "\n",
    "for featuredir in ['hinge', 'cohinge', 'quadhinge', 'deltahinge', 'tcchinge', 'junclets']:\n",
    "    print(featuredir)\n",
    "    if featuredir == 'junclets':\n",
    "        results_dict = np.load('./Data/' + dataset.name + '/validation_results/' + featuredir + '_' + str(dataset.cb_size) + '_validation.npy', allow_pickle=True)\n",
    "        results_dict = results_dict.item()\n",
    "    else:\n",
    "        results_dict = np.load('./Data/' + dataset.name + '/validation_results/' + featuredir + '_validation.npy', allow_pickle=True)\n",
    "        results_dict = results_dict.item()\n",
    "\n",
    "    results_aug_dict = np.load('./Data/' + dataset.name + '/validation_results/' + featuredir + '_validation_aug.npy', allow_pickle=True)\n",
    "    results_aug_dict = results_aug_dict.item()\n",
    "\n",
    "    mae = np.asarray(results_dict['MAE'])\n",
    "    mae_aug = np.asarray(results_aug_dict['MAE'])\n",
    "\n",
    "    cs_0 = np.asarray(results_dict['CS_0'])\n",
    "    cs_0_aug = np.asarray(results_aug_dict['CS_0'])\n",
    "\n",
    "    anova_mae = f_oneway(mae.flatten(), mae_aug.flatten())\n",
    "    anova_cs0 = f_oneway(cs_0.flatten(), cs_0_aug.flatten())\n",
    "\n",
    "    print(\"MAE: \", anova_mae)\n",
    "    print(\"CS (alpha = 0): \", anova_cs0)\n",
    "\n",
    "    if dataset.name == MPS.name:\n",
    "        cs_25 = np.asarray(results_dict['CS_25'])\n",
    "        cs_25_aug = np.asarray(results_aug_dict['CS_25'])\n",
    "        anova_cs25 = f_oneway(cs_25.flatten(), cs_25_aug.flatten())\n",
    "        print(\"CS (alpha = 25): \", anova_cs25)\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b1d2e8c8e0dae5cc18d8c1ce376cecf2defda75ea962015ba4a05eb1f89d55f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
